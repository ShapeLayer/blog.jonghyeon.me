---
layout: post
title: "Rich feature hierarchies for accurate object detection and semantic segmentation 리뷰"
date: '2024-11-08'
categories: [paper-review]
tags: [paper-review]
---

&lt;Rich feature hierarchies for accurate object detection and semantic segmentation&gt;은 R-CNN을 제안한 논문입니다. 이 연구를 계기로 물체 인식에 딥러닝을 도입하기 시작하였고, 곧이어 Fast RCNN, Faster RCNN으로 이어지게 됩니다.

R-CNN이 제안되기 이전까지 2004년 발표된 &lt;Distinctive Image Features from Scale-Invariant Keypoints&gt;의 SIFT, 2005년 발표된 &lt;Histograms of Oriented Gradients for Human Detection&gt;의 HOG가 자주 사용되었습니다.

둘 모두 R-CNN이 제안된 2013년으로부터 꽤 오래된 것이었고, 그 사이에 발표된 변형들은 PASCAL VOC 기준으로 크지 않은 수준의 성능 향상만 있었을 뿐입니다.

R-CNN은 획기적인 성능 향상을 도모하기 위해, 이전까지 후보군 탐색에 널리 사용되던 Sliding Window를 CNN으로 대체하고, 당시에 널리 사용되던 이미지 분류 모델, AlexNet을 사용합니다. 그 결과 논문 발표 이전까지 VOC 2012에 기록된 최고 성능보다, 30% 이상 더 개선된 성능을 보일 수 있었습니다.

## R-CNN으로 물체 탐색

![image.png](/static/posts/2024-11-08-paper-arxiv-1311.2524v5/image.png)  

R-CNN은 카테고리에 관계 없이 모든 물체 범위 탐색, 탐색된 물체 범위를 입력으로 받는 CNN, 그리고 클래스 분류를 처리하는 선형 SVM으로 구성됩니다. 

**Region Proposal**

![Selective Search for Object Recogniution JRR Uijlings](/static/posts/2024-11-08-paper-arxiv-1311.2524v5/image%201.png)

_Selective Search for Object Recogniution by JRR Uijlings_


우선 적당한 개수의 Region Proposal을 생성합니다. 구체적으로는 &lt;An open source convolutional architecture for fast feature embedding&gt;의 Caffe 구조를 사용합니다. 이 논문에서는 2,000개의 Region proposal을 생성했습니다. 이렇게 생성한 Proposal을 이후 과정에서 사용할 수 있도록 일관된 크기, $227 \times 227$로 변환합니다.

그 뒤에 변환한 데이터를 CNN과 FC 레이어에 통과시켜 Feature Extraction 과정을 수행합니다. Region Proposal을 생성하는 과정 중에 Region Proposal의 크기를 일관되게 조정하는 이유가 이 과정에서 CNN 이후에 데이터를 Fully-connected 레이어를 통과시키기 때문입니다.

Feature Extraction 과정을 위해 미리 Feature Extractor가 미리 학습된 ImageNet을 사용합니다. 이어서 CNN을 fine-tuning 할 때 Ground Truth와 추출된 영역<sup>SS Predicted</sup>의 IoU가 0.5 아래인 것들은 배경으로 처리합니다.

**Region Classification**

CNN의 출력 feature map은 SVM(Support Vector Machine)을 사용하여 클래스를 분류합니다.

학습 과정에서는 IoU가 0.3 이상인 물체들만 SVM의 학습에 사용합니다.

CNN의 fine-tuning과 SVM 학습 중의 IoU가 서로 다른 이유, 클래스 분류에 Softmax가 아니라 SVM을 사용한 이유 모드 경험적으로 더 좋은 결과를 내었기 때문입니다.

SVM 대신 21-way softmax 회귀 분류기를 사용했더니 VOC 2007 기준으로 mAP 값이 54.2%에서 50.9%로 떨어졌다고 합니다.

## 구성 요소를 제거하면 어떻게 될까

연구팀은 전체 모델에서 몇 가지 구성 요소를 제거하면 어떻게 되는지, 이를 통해 각각의 단계가 얼마나 중요한 역할을 하는지 확인하기도 합니다.

### 파인 튜닝을 하지 않을 때, 각 레이어의 성능

pool5 레이어는 CNN 구조에서 마지막 합성곱 레이어에 max-pooling을 적용하는 레이어입니다. 이 레이어는 $6 \times 6 \times 256$차원의 feature 맵을 생성합니다.

fc6 레이어는 pool5를 fully connect하여 $4096$ 크기의 벡터를, fc7 레이어는 fc6으로부터 fully connect하여 $4096$ 차원의 벡터를 생성합니다.

PASCAL에 대해 파인 튜닝을 하지 않고 ILSVRC 2012에 대해서만 학습한 CNN은 fc7이 fc6보다 일반화 성능이 떨어집니다. 다시 말해서, mAP를 유지한 채 fc7, CNN 매개변수의 약 29%를 제거할 수 있다는 것입니다.

더 나아가 fc7과 fc6을 모두 제거했을 때도 나름 좋은 결과를 보였는데, 이것은 CNN 전체 매개변수의 96%를 제거하고 6%만을 사용하여 계산된 것입니다.

### 파인 튜닝을 했을 때, 각 레이어의 성능

VOC 2007에 대해 파인 튜닝한 결과 mAP가 8%p 오른 54.2%로 향상되었습니다. fc6과 fc7에 의한 성능 향상이 pool5에 의한 성능 향상보다 컸습니다. 다시 말해 ImageNet으로부터 학습한 pool5의 feature가 일반화된 레이어이고, fc6과 fc7은 파인 튜닝에 활용되었다고 볼 수 있습니다.

## 인식 오류와 바운딩 박스 회귀

인식 오류 평가에는 &lt;Diagnosing Error in Object Detectors&gt;의 검출분석기를 적용하고, 로스 평가에는 &lt;Object Detection with Discriminatively Trained Part Based Models&gt;의 Deformable Part Models(DPM), 바운딩 박스 회귀를 모티브로 회귀 모델을 도입했습니다.

구체적으로는 검출된 각 결과에 대해 클래스별 탐지 SVM으로 점수를 매긴 후, 회귀 모델을 사용하여 바운딩 박스의 새 위치를 예측합니다.

예측 바운딩 박스 정보 $P^i=(P^i_x, P^i_y, P^i_w, P^i_h)$(중심$x$, 중심$y$, 너비, 높이)와 $G^i=(G^i_x, G^i_y, G^i_w, G^i_h)$에 대해 ${(P^i, G^i)}_{i=1, ..., N}$인 $N$개의 페어를, $P$를 $G$로 매핑하는 학습에 활용합니다. 

이 매핑, 변환은 $d_x(P)$, $d_y(P)$, $d_w(P)$, $d_h(P)$을 사용해 매개화합니다. $d_x(P)$, $d_y(P)$는 척도 불변 변환을, $d_w(P)$, $d_h(P)$는 바운딩 박스의 너비와 높이에 대해 로그 공간 변환을 나타냅니다.

$$
\begin{aligned}
\^{G}_x &= P_wd_x(P) + P_x \\
\^{G}_y &= P_hd_y(P) + P_y \\
\^{G}_w &= P_w\exp (d_w(P)) \\
\^{G_h} &= P_h\exp (d_h(P))
\end{aligned}
$$

$$
\begin{aligned}
d_x(P) &= (\^{G}_x - P_x) / P_w \\
d_y(P) &= (\^{G}_y - P_y) / P_h \\
d_w(P) &= \log (G_w) - \log P_w \\
d_h(P) &= \log (G_h) - \log P_h \\
\end{aligned}
$$

### 왜 $x$, $y$에는 척도 불변 변환을, $w$, $h$에는 로그 공간 변환을 사용했는가?

_논문을 읽으면서 제대로 이해하지 못했던 부분 중 하나는 서로 다른 변환을 채택했다는 점입니다._  

$x$, $y$는 바운딩 박스의 위치를 표현하는데 사용됩니다. 그리고 위치의 이동은 박스의 크기와 비례해서 움직여야 할 수 있습니다. 작은 바운딩 박스와 큰 바운딩 박스가 같은 값을 이동한다면, 작은 박스에게는 큰 변화가 큰 박스에게는 작은 변화일 수 있습니다.  

그래서 위치가 박스의 크기에 비례해 조정되도록 했습니다. 이렇게 하여 중심점의 위치가 바운딩 박스의 크기에 따라 유동적으로 변하도록 할 수 있고, 척도 불변 변환이라고 부르는 이유입니다.  

$d_w$, $d_h$는 크기와 비율의 변화에 대한 값입니다. 로그 공간에서의 모델링은 이 크기와 비율의 변화를 예측하는데 유용합니다.

예를 들어 너비와 높이가 동시에 두 배가 되어야 한다면 같은 비율적 변화가 일관되게 반영하도록 할 때, 로그는 곱셈을 "덧셈스럽게" 처리할 수 있으므로 선형 회귀 모델을 더 효과적으로 사용할 수 있습니다.

### 회귀 학습에 사용하기

각 $x$, $y$, $w$, $h$에 대해 $d(P)$는 P의 pool5 feature(= $\phi _5(P)$)를 입력으로 갖는 선형 함수로 모델링됩니다.

$$
d(P)=\mathbf{w}^\mathbf{T}\phi_5(P)
$$

여기서 $\mathbf{w} ^T$는 학습 가능한 파라미터이고, 학습 과정에서 정규화된 릿지 회귀(정규화된 최소 제곱 목표)를 최적화하여 학습합니다.

$$
\mathbf{w} = \argmin_{\^w} \sum_{i}^{N}(t^i - \^\textbf{w}^\textbf{T}\phi_5(P^i))^2 + \lambda||\^\textbf{w}||^2
$$

연구팀은 이렇게 회귀를 구현하는 과정에서 두 개의 문제가 있었다고 서술합니다.

1. 정규화의 도입과 조정: 연구 과정에서는 $\lambda=1000$으로 설정했습니다.
2. 서로 무관계한 $(P, G)$가 학습에 투입되지 않도록 조정
    $P$가 모든 $G$에 대해 무관하게 멀리 떨어져 있다면, $P$를 $G$로 변환하려고 하기보다 학습에서 제외하도록 합니다. 구체적으로는 IoU가 0.6 이상이 아니면 제외합니다.

연구 과정에서는 $P$ 평가, 예측을 한 번씩만 수행했는데, 반복해도 결과가 개선되지 않았기 때문이라고 합니다.
